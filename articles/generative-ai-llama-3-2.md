---
title: "Llama-3.2-90B-Vision-Instructã‚’OCI Generative AI Serviceã‹ã‚‰è©¦ã™"
emoji: "ğŸ¦™"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["OCI"]
published: true
---

## ã¯ã˜ã‚ã«

OCI(Oracle Cloud Infrastructure)ã® Generative AI Service ã¨ã„ãˆã°ã€Cohere ç¤¾ã® Command ãƒ¢ãƒ‡ãƒ«ã¨ã„ã†ã‚¤ãƒ¡ãƒ¼ã‚¸ãŒå€‹äººçš„ã«ã¯å¼·ã‹ã£ãŸã§ã™ãŒã€å®Ÿã¯ãƒªãƒªãƒ¼ã‚¹å½“åˆã‹ã‚‰ Llama ã‚‚ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚Cohere ç¤¾ãŒæä¾›ã—ã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã¯åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’é™¤ãã€ç¾çŠ¶ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã«å¯¾å¿œã§ãã‚‹ã‚‚ã®ã¯ã‚ã‚Šã¾ã›ã‚“ã®ã§ã€ãã®ã‚ˆã†ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã§ã¯ LLama ã‚’é¸æŠã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚‚ã‚ã‚‹ã‹ãªï¼Ÿã¨ã„ã†ã“ã¨ã§ã€OCI SDK for Python ã‹ã‚‰ `Llama-3.2-90B-Vision-Instruct` ã‚’ä½¿ã†æ–¹æ³•ã‚’è§£èª¬ã—ã¾ã™ âœ‹

## OCI SDK ã§æ“ä½œã™ã‚‹

æœ€å°é™ã®ã‚³ãƒ¼ãƒ‰ä¾‹ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

```py
import base64
from oci.auth.signers.instance_principals_security_token_signer import InstancePrincipalsSecurityTokenSigner
from oci.generative_ai_inference.generative_ai_inference_client import GenerativeAiInferenceClient
from oci.generative_ai_inference.models import (
    ImageContent,
    ImageUrl,
    TextContent,
    ChatDetails,
    OnDemandServingMode,
    GenericChatRequest,
    Message
)

compartment_id = "<your-compartment-id>"
image_path = "<your-image-path>"

# ... 1
client = GenerativeAiInferenceClient(
    config={},
    signer=InstancePrincipalsSecurityTokenSigner(),
    service_endpoint="https://inference.generativeai.ap-osaka-1.oci.oraclecloud.com"
)

def get_image_base64(image_path: str):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode()

def chat_with_image(base64_image_content: str) -> str:
    response = client.chat(
        chat_details=ChatDetails(
            compartment_id=compartment_id,
            serving_mode=OnDemandServingMode(
                model_id="meta.llama-3.2-90b-vision-instruct",
            ),
            # ... 2
            chat_request=GenericChatRequest(
                messages=[
                    Message(
                        role="SYSTEM",
                        content=[
                            TextContent(
                                text="Please explain about given images."
                            )
                        ]
                    ),
                    Message(
                        role="USER",
                        content=[ImageContent(
                            # ... 3
                            image_url=ImageUrl(
                                url=f"data:image/jpg;base64,{base64_image_content}"
                            )
                        )]
                    )
                ]
            )
        )
    )
    return response.data

def main():
    base64_image_content = get_image_base64(image_path)
    response = chat_with_image(base64_image_content)
    print(f"{response=}")


if __name__ == "__main__":
    main()
```

ãƒã‚¤ãƒ³ãƒˆã‚’ç°¡å˜ã«è§£èª¬ã—ã¾ã™ã€‚

### `GenerativeAIInferenceClient` ã®åˆæœŸåŒ–

ä»Šå›ã€å®Ÿè£…ã—ãŸ Python ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¯ OCI Compute ä¸Šã§å®Ÿè¡Œã—ã¦ã„ã‚‹ã®ã§å½“è©² Compute ã‚’å«ã‚€å‹•çš„ã‚°ãƒ«ãƒ¼ãƒ—ã«é©åˆ‡ãª IAM Policy(e.g. `allow dynamic-group <hoge> to use generative-ai-family in compartment <hoge>`) ã‚’æ›¸ãã“ã¨ã§ Generative AI Service ã«å¯¾ã™ã‚‹èªå¯åˆ¶å¾¡ã‚’å®Ÿæ–½ã—ã¦ã„ã¾ã™ã€‚

```py
client = GenerativeAiInferenceClient(
    config={},
    signer=InstancePrincipalsSecurityTokenSigner(),
    service_endpoint="https://inference.generativeai.ap-osaka-1.oci.oraclecloud.com"
)
```

IAM User ãƒ™ãƒ¼ã‚¹ã§åˆ¶å¾¡ï¼ˆAPI Key ã‚’ç”¨ã„ãŸåˆ¶å¾¡ï¼‰ã‚’è¡Œã„ãŸã„å ´åˆã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ã«æ›¸ãç›´ã™ã¨è‰¯ã„ã§ã—ã‚‡ã†ã€‚

```py
config = from_file("~/.oci/config", "DEFAULT")
client = GenerativeAiInferenceClient(
    config=config,
    service_endpoint="https://inference.generativeai.ap-osaka-1.oci.oraclecloud.com"
)
```

### `chat_request` ã«ã¯ã€`GenericChatRequest` ã‚’ç”¨ã„ã‚‹

`chat_request` ã«ã¯ã€[BaseChatRequest](https://docs.oracle.com/en-us/iaas/tools/python/2.151.0/api/generative_ai_inference/models/oci.generative_ai_inference.models.BaseChatRequest.html) ã®ã‚µãƒ–ã‚¯ãƒ©ã‚¹ã§ã‚ã‚‹ `GenericChatRequest` ã‹ `CohereChatRequest` ã‚’ç”¨ã„ã¾ã™ãŒã€ä»Šå›ã¯ Llama ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ `GenericChatRequest` ã‚’ç”¨ã„ã¾ã™ã€‚

```py
chat_request=GenericChatRequest(
    messages=[
        Message(
            # ... çœç•¥ ...
        ),
        Message(
            # ... çœç•¥ ...
        )
    ]
)
```

### `ImageUrl` ã®å½¢å¼ã«æ³¨æ„ã™ã‚‹

`ImageUrl` ã§æŒ‡å®šå¿…é ˆãªã®ã¯ã€`url` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã ã‘ã§ã™ãŒã€`url` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æŒ‡å®šã¯ä¸€ç™–ã‚ã‚Šã¾ã™ã€‚[API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ - oci.generative_ai_inference.models.ImageUrl](https://docs.oracle.com/en-us/iaas/tools/python/2.151.0/api/generative_ai_inference/models/oci.generative_ai_inference.models.ImageUrl.html#oci.generative_ai_inference.models.ImageUrl) ã‚’ã¿ã¦ã¿ã‚‹ã¨ä»¥ä¸‹ã®ã‚ˆã†ãªè¨˜è¼‰ãŒã‚ã‚Šã¾ã™ã€‚

```txt
[Required] Gets the url of this ImageUrl. The base64 encoded image data.

Example for a png image:
{
  â€œtypeâ€: â€œIMAGEâ€, â€œimageUrlâ€: {
    â€œurlâ€: â€œdata:image/png;base64,<base64 encoded image content>â€
  }
}
```

ã¨ã„ã†ã“ã¨ã§ã€`url` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ã¯ã„ãã¤ã‹ã® Prefix ã¨ Base64 ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¸¡ã›ã°è‰¯ã„ã¨ã„ã†ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚

```py
Message(
    role="USER",
    content=[ImageContent(
        # ... 3
        image_url=ImageUrl(
            url=f"data:image/jpg;base64,{base64_image_content}"
        )
    )]
)
```

### å®Ÿè¡Œã—ã¦ã¿ãŸ

ä¸Šè¨˜ã® Python ãƒ•ã‚¡ã‚¤ãƒ«ã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä»¥ä¸‹ã®ç”»åƒã‚’ç½®ã„ã¦ç¢ºèªã—ã¦ã¿ã¾ã—ãŸã€‚

![koinobori](/images/generative-ai-llama-3.2/koinobori.jpg)

```py
response={
  "chat_response": {
    "api_format": "GENERIC",
    "choices": [
      {
        "finish_reason": "stop",
        "index": 0,
        "logprobs": {
          "text_offset": null,
          "token_logprobs": null,
          "tokens": null,
          "top_logprobs": null
        },
        "message": {
          "content": [
            {
              "text": "The image depicts a scene featuring three large koi fish-shaped windsocks suspended from a tall pole against a blue sky with white clouds.\n\n**Key Features:**\n\n*   **Koi Fish Windsocks:** The windsocks are designed to resemble koi fish, a symbol of good luck and prosperity in Japanese culture. They are typically flown during the Japanese holiday of Children's Day (Kodomo no Hi) on May 5th.\n*   **Design and Colors:** Each windsock features a different design and color scheme, adding visual interest to the scene. The top windsock is white with a black tail and features Japanese characters in red, while the middle windsock is also white but has a pink body and features more Japanese characters. The bottom windsock is green and pink, with a more intricate design.\n*   **Suspension:** The windsocks are attached to a tall pole that appears to be made of metal or wood. The pole is adorned with a decorative top, which adds to the festive atmosphere of the scene.\n*   **Background:** The background of the image is a blue sky with white clouds, which provides a serene and peaceful contrast to the vibrant colors of the windsocks.\n\n**Cultural Significance:**\n\n*   **Children's Day:** The image is likely taken during the celebrations of Children's Day, a Japanese holiday that honors the health and happiness of children. The koi fish windsocks are a traditional symbol of this holiday, representing good luck and prosperity for children.\n*   **Japanese Culture:** The image showcases elements of Japanese culture, including the design and colors of the windsocks, which are inspired by traditional Japanese art and craftsmanship.\n\n**Overall Impression:**\n\nThe image conveys a sense of joy and celebration, with the colorful windsocks and festive atmosphere evoking feelings of happiness and optimism. The use of traditional Japanese symbols and designs adds a layer of cultural significance to the image, making it a unique and interesting representation of Japanese culture.",
              "type": "TEXT"
            }
          ],
          "name": null,
          "role": "ASSISTANT",
          "tool_calls": []
        }
      }
    ],
    "time_created": "2025-05-08T06:55:34.641000+00:00"
  },
  "model_id": "meta.llama-3.2-90b-vision-instruct",
  "model_version": "1.0.0"
}
```

ã¨è¿”å´ã•ã‚Œã€ç¢ºã‹ã«ç”»åƒã«å¯¾ã™ã‚‹èª¬æ˜ãŒé©åˆ‡ã«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚ã¡ãªã¿ã«ã€[Hugging Face ã® Llama-3.2-90B-Vision-Instruct ã® Model Card](https://huggingface.co/meta-llama/Llama-3.2-90B-Vision-Instruct) ã‚’ã¿ã‚‹ã¨ã‚ã‹ã‚Šã¾ã™ãŒã€ç”»åƒ + ãƒ†ã‚­ã‚¹ãƒˆã®å ´åˆã¯ã€è‹±èªã—ã‹ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ãªã„ãŸã‚æ—¥æœ¬èªã§ã®å¿œç­”ãŒã—ãŸã„å ´åˆã¯ã€åˆ¥ã®å¤šè¨€èªå¯¾å¿œã®ãƒ¢ãƒ‡ãƒ«ï¼ˆä¾‹ãˆã°ã€Cohere ãªã©ï¼‰ã‚’ç”¨ã„ã¦å…¥åŠ›ã¨å‡ºåŠ›ã‚’ç¿»è¨³ã™ã‚‹ãªã©ã®å·¥å¤«ãŒå¿…è¦ã§ã—ã‚‡ã†ã€‚

## çµ‚ã‚ã‚Šã«

ä»Šå›ã¯ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã«å¯¾å¿œã—ãŸ Llama-3.2-90B-Vision-Instruct ã‚’ OCI ã® Generative AI Service ã‹ã‚‰è©¦ã—ã¦ã¿ã¾ã—ãŸ âœ‹ ä¸€éƒ¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æŒ‡å®šæ–¹æ³•ã«ç™–ãŒã‚ã‚Šã¾ã™ã®ã§ã€åŒã˜ã‚ˆã†ãªã¨ã“ã‚ã§æ‚©ã‚“ã§ã„ã‚‹æ–¹ã®ä¸€åŠ©ã«ãªã‚Œã°å¹¸ã„ã§ã™ã€‚

## å‚è€ƒ

https://huggingface.co/meta-llama/Llama-3.2-90B-Vision-Instruct

https://docs.oracle.com/en-us/iaas/tools/python/2.151.0/api/generative_ai_inference/models/oci.generative_ai_inference.models.ImageUrl.html#oci.generative_ai_inference.models.ImageUrl
